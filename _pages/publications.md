---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<!---
{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}
-->

<!---
{% include base_path %}
-->

<!---
{% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
-->

# Talk Slides
When Do Neural Networks Have No Bad Local Minima? [slides](https://www.dropbox.com/s/zx2gnk7yb5hv2nk/RuoyuSun_andscape_public.pdf?dl=0)

# JOURNAL ARTICLES and PREPRINTS
* [Over-Parameterized Deep Neural Networks Have No Strict Local Minima For Any Continuous Activations](https://arxiv.org/pdf/1812.11039.pdf), <\br >
Dawei Li, Tian Ding, Ruoyu Sun, preprint. 
* [On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization](https://arxiv.org/abs/1808.02941), <\br >
Xiangyi Chen, Sijia Liu, Ruoyu Sun, Mingyi Hong.  Part of the paper has been accepted to ICLR 2019.
